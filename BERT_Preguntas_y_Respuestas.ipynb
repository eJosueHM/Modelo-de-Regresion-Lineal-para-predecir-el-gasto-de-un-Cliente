{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Preguntas y Respuestas.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eJosueHM/Modelo-de-Regresion-Lineal-para-predecir-el-gasto-de-un-Cliente/blob/master/BERT_Preguntas_y_Respuestas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e2o65JiJ4R-"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "223xiMP3K9kt"
      },
      "source": [
        "# Importar\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
        "the_model = 'mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es'\n",
        "tokenizer = AutoTokenizer.from_pretrained(the_model, do_lower_case=False)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(the_model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDlFhBfJLj2d"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2Em_dKRLphz"
      },
      "source": [
        "# Ejemplo tokenización\n",
        "contexto = 'Yo soy Miguel'\n",
        "pregunta = '¿cómo me llamo?'\n",
        "\n",
        "encode = tokenizer.encode_plus(pregunta, contexto, return_tensors='pt')\n",
        "input_ids = encode['input_ids'].tolist()\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "for id, token in zip(input_ids[0], tokens):\n",
        "  print('{:<12} {:>6}'.format(token, id))\n",
        "  print('')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KryC3O2aMnp-"
      },
      "source": [
        "# Ejemplo de inferencia (pregunta-respuesta)\n",
        "nlp = pipeline('question-answering', model=model, tokenizer=tokenizer)\n",
        "salida = nlp({'question':pregunta, 'context':contexto})\n",
        "print(salida)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA6f0-DYNu2L"
      },
      "source": [
        "from textwrap import wrap\n",
        "\n",
        "def pregunta_respuesta(model, contexto, nlp):\n",
        "\n",
        "  # Imprimir contexto\n",
        "  print('Contexto:')\n",
        "  print('-----------------')\n",
        "  print('\\n'.join(wrap(contexto)))\n",
        "\n",
        "  # Loop preguntas-respuestas:\n",
        "  continuar = True\n",
        "  while continuar:\n",
        "    print('\\nPregunta:')\n",
        "    print('-----------------')\n",
        "    pregunta = str(input())\n",
        "\n",
        "    continuar = pregunta!=''\n",
        "\n",
        "    if continuar:\n",
        "      salida = nlp({'question':pregunta, 'context':contexto})\n",
        "      print('\\nRespuesta:')\n",
        "      print('-----------------')\n",
        "      print(salida['answer'])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64bUn-bnOz9b"
      },
      "source": [
        "pregunta_respuesta(model, contexto, nlp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSq3FUAxO6aJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473a447a-3751-461f-d2c9-d09f353d22fc"
      },
      "source": [
        "contexto = \"Mi nombre es Josue Huaman, soy de Huancayo pero vivo en Lima, actualmente trabajo como supervisor ssoma en una empresa que fabrica cables electricos, tengo 32 años y soy ingeniero industrial\"\n",
        "pregunta_respuesta(model, contexto, nlp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contexto:\n",
            "-----------------\n",
            "Mi nombre es Josue Huaman, soy de Huancayo pero vivo en Lima,\n",
            "actualmente trabajo como supervisor ssoma en una empresa que fabrica\n",
            "cables electricos, tengo 32 años y soy ingeniero industrial\n",
            "\n",
            "Pregunta:\n",
            "-----------------\n",
            "como me llamo?\n",
            "\n",
            "Respuesta:\n",
            "-----------------\n",
            "Josue Huaman\n",
            "\n",
            "Pregunta:\n",
            "-----------------\n",
            "cuantos años tengo?\n",
            "\n",
            "Respuesta:\n",
            "-----------------\n",
            "32\n",
            "\n",
            "Pregunta:\n",
            "-----------------\n",
            "de donde soy\n",
            "\n",
            "Respuesta:\n",
            "-----------------\n",
            "Huancayo pero vivo en Lima\n",
            "\n",
            "Pregunta:\n",
            "-----------------\n",
            "que soy\n",
            "\n",
            "Respuesta:\n",
            "-----------------\n",
            "ingeniero industrial\n",
            "\n",
            "Pregunta:\n",
            "-----------------\n",
            "en donde trabajo?\n",
            "\n",
            "Respuesta:\n",
            "-----------------\n",
            "supervisor ssoma\n",
            "\n",
            "Pregunta:\n",
            "-----------------\n",
            "en que empresa trabajo?\n",
            "\n",
            "Respuesta:\n",
            "-----------------\n",
            "ssoma\n",
            "\n",
            "Pregunta:\n",
            "-----------------\n",
            "como se llama la empresa?\n",
            "\n",
            "Respuesta:\n",
            "-----------------\n",
            "cables electricos\n",
            "\n",
            "Pregunta:\n",
            "-----------------\n",
            "que fabrica la empresa en donde trabajo?\n",
            "\n",
            "Respuesta:\n",
            "-----------------\n",
            "cables electricos\n",
            "\n",
            "Pregunta:\n",
            "-----------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1lvHNbFPI2D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}